{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08a49de",
   "metadata": {},
   "source": [
    "# Feature Engineering Debug Notebook\n",
    "\n",
    "This notebook will help identify and fix issues in the feature engineering process of the bearing anomaly detection pipeline. We'll step through each operation to validate the data at each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd6b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Required Libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7615bb",
   "metadata": {},
   "source": [
    "## 2. Load Sample Data\n",
    "\n",
    "We'll load a small subset of the bearing data to test the feature engineering process. This will make it easier to debug any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f771b269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 17:21:25,926 - INFO - Loading 5 files for testing\n",
      "2025-11-06 17:21:25,969 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.06.24 with shape (20480, 8)\n",
      "2025-11-06 17:21:25,969 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.06.24 with shape (20480, 8)\n",
      "2025-11-06 17:21:34,462 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.09.13 with shape (20480, 8)\n",
      "2025-11-06 17:21:34,462 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.09.13 with shape (20480, 8)\n",
      "2025-11-06 17:21:43,079 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.14.13 with shape (20480, 8)\n",
      "2025-11-06 17:21:43,079 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.14.13 with shape (20480, 8)\n",
      "2025-11-06 17:21:51,738 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.19.13 with shape (20480, 8)\n",
      "2025-11-06 17:21:51,738 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.19.13 with shape (20480, 8)\n",
      "2025-11-06 17:22:00,482 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.24.13 with shape (20480, 8)\n",
      "2025-11-06 17:22:00,482 - INFO - Loaded file ../data/1st_test\\2003.10.22.12.24.13 with shape (20480, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Summary:\n",
      "Shape: (102400, 7)\n",
      "\n",
      "First few rows:\n",
      "       mean       std       rms      kurt      skew    ptp  time\n",
      "0 -0.101000  0.053137  0.114125 -1.329223  0.163090  0.161     0\n",
      "1 -0.090750  0.068159  0.113496 -0.754834  0.475306  0.212     1\n",
      "2 -0.106875  0.070464  0.128013 -1.494880  0.314280  0.190     2\n",
      "3 -0.135125  0.035974  0.139832 -1.741211  0.206636  0.100     3\n",
      "4 -0.147625  0.067487  0.162320 -1.214865 -0.298120  0.198     4\n",
      "\n",
      "Data Types:\n",
      "mean    float64\n",
      "std     float64\n",
      "rms     float64\n",
      "kurt    float64\n",
      "skew    float64\n",
      "ptp     float64\n",
      "time      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess a small subset of data\n",
    "path = \"../data/1st_test/\"\n",
    "files = sorted(glob.glob(os.path.join(path, \"*[!.]*\")))[:5]  # Load first 5 files for testing\n",
    "logger.info(f\"Loading {len(files)} files for testing\")\n",
    "\n",
    "stats = []\n",
    "for f in files:\n",
    "    try:\n",
    "        data = np.loadtxt(f, delimiter='\\t')  # Add explicit delimiter\n",
    "        logger.info(f\"Loaded file {f} with shape {data.shape}\")\n",
    "        \n",
    "        # Calculate statistics per row\n",
    "        row_stats = []\n",
    "        for row in data:\n",
    "            mean_ = np.mean(row)\n",
    "            std_ = np.std(row)\n",
    "            rms_ = np.sqrt(np.mean(row**2))\n",
    "            kurt_ = pd.Series(row).kurt()\n",
    "            skew_ = pd.Series(row).skew()\n",
    "            ptp_  = np.ptp(row)\n",
    "            row_stats.append([mean_, std_, rms_, kurt_, skew_, ptp_])\n",
    "        stats.extend(row_stats)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading file {f}: {str(e)}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(stats, columns=['mean', 'std', 'rms', 'kurt', 'skew', 'ptp'])\n",
    "df['time'] = np.arange(len(df))\n",
    "\n",
    "print(\"\\nDataFrame Summary:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926ab54",
   "metadata": {},
   "source": [
    "## 3. Debug Feature Engineering\n",
    "\n",
    "Let's step through the rolling statistics calculation carefully and validate the data at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46381d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 17:22:19,222 - INFO - Starting feature engineering process\n",
      "2025-11-06 17:22:19,239 - INFO - \n",
      "Processing window size 3\n",
      "2025-11-06 17:22:19,246 - INFO - Rolling mean (window=3) - First 5 values: [0.11412493154433873, 0.1138102630862502, 0.11854456969579537, 0.12711345756173467, 0.14338809773718905]\n",
      "2025-11-06 17:22:19,254 - INFO - Rolling std (window=3) - First 5 values: [0.0, 0.00044500840107982825, 0.008206094896969295, 0.013191033320085763, 0.017427496692453547]\n",
      "2025-11-06 17:22:19,239 - INFO - \n",
      "Processing window size 3\n",
      "2025-11-06 17:22:19,246 - INFO - Rolling mean (window=3) - First 5 values: [0.11412493154433873, 0.1138102630862502, 0.11854456969579537, 0.12711345756173467, 0.14338809773718905]\n",
      "2025-11-06 17:22:19,254 - INFO - Rolling std (window=3) - First 5 values: [0.0, 0.00044500840107982825, 0.008206094896969295, 0.013191033320085763, 0.017427496692453547]\n",
      "2025-11-06 17:22:19,257 - INFO - \n",
      "Processing window size 5\n",
      "2025-11-06 17:22:19,263 - INFO - Rolling mean (window=5) - First 5 values: [0.11412493154433873, 0.1138102630862502, 0.11854456969579537, 0.12386632605738569, 0.1315569638768135]\n",
      "2025-11-06 17:22:19,272 - INFO - Rolling std (window=5) - First 5 values: [0.0, 0.00044500840107982825, 0.008206094896969295, 0.012576871314462569, 0.020355903797018713]\n",
      "2025-11-06 17:22:19,257 - INFO - \n",
      "Processing window size 5\n",
      "2025-11-06 17:22:19,263 - INFO - Rolling mean (window=5) - First 5 values: [0.11412493154433873, 0.1138102630862502, 0.11854456969579537, 0.12386632605738569, 0.1315569638768135]\n",
      "2025-11-06 17:22:19,272 - INFO - Rolling std (window=5) - First 5 values: [0.0, 0.00044500840107982825, 0.008206094896969295, 0.012576871314462569, 0.020355903797018713]\n",
      "2025-11-06 17:22:19,276 - INFO - \n",
      "Processing window size 10\n",
      "2025-11-06 17:22:19,281 - INFO - Rolling mean (window=10) - First 5 values: [0.11412493154433873, 0.1138102630862502, 0.11854456969579537, 0.12386632605738569, 0.1315569638768135]\n",
      "2025-11-06 17:22:19,289 - INFO - Rolling std (window=10) - First 5 values: [0.0, 0.00044500840107982825, 0.008206094896969295, 0.012576871314462569, 0.020355903797018713]\n",
      "2025-11-06 17:22:19,276 - INFO - \n",
      "Processing window size 10\n",
      "2025-11-06 17:22:19,281 - INFO - Rolling mean (window=10) - First 5 values: [0.11412493154433873, 0.1138102630862502, 0.11854456969579537, 0.12386632605738569, 0.1315569638768135]\n",
      "2025-11-06 17:22:19,289 - INFO - Rolling std (window=10) - First 5 values: [0.0, 0.00044500840107982825, 0.008206094896969295, 0.012576871314462569, 0.020355903797018713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RMS statistics:\n",
      "count    102400.000000\n",
      "mean          0.120473\n",
      "std           0.025734\n",
      "min           0.033701\n",
      "25%           0.103064\n",
      "50%           0.118501\n",
      "75%           0.135381\n",
      "max           0.365391\n",
      "Name: rms, dtype: float64\n",
      "\n",
      "Validation for window size 3:\n",
      "Number of NaN values in roll_mean_3: 0\n",
      "Number of NaN values in roll_std_3: 0\n",
      "\n",
      "Validation for window size 5:\n",
      "Number of NaN values in roll_mean_5: 0\n",
      "Number of NaN values in roll_std_5: 0\n",
      "\n",
      "Validation for window size 10:\n",
      "Number of NaN values in roll_mean_10: 0\n",
      "Number of NaN values in roll_std_10: 0\n",
      "\n",
      "Final NaN check:\n",
      "mean            0\n",
      "std             0\n",
      "rms             0\n",
      "kurt            0\n",
      "skew            0\n",
      "ptp             0\n",
      "time            0\n",
      "roll_mean_3     0\n",
      "roll_std_3      0\n",
      "roll_mean_5     0\n",
      "roll_std_5      0\n",
      "roll_mean_10    0\n",
      "roll_std_10     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Debug feature engineering process\n",
    "logger.info(\"Starting feature engineering process\")\n",
    "\n",
    "# Create a copy of the DataFrame for safety\n",
    "df_debug = df.copy()\n",
    "\n",
    "# Print initial statistics\n",
    "print(\"Initial RMS statistics:\")\n",
    "print(df_debug['rms'].describe())\n",
    "\n",
    "# Test rolling calculations with different windows\n",
    "windows = [3, 5, 10]\n",
    "for w in windows:\n",
    "    logger.info(f\"\\nProcessing window size {w}\")\n",
    "    \n",
    "    # Calculate rolling mean\n",
    "    roll_mean = df_debug['rms'].rolling(window=w, min_periods=1).mean()\n",
    "    logger.info(f\"Rolling mean (window={w}) - First 5 values: {roll_mean.head().tolist()}\")\n",
    "    df_debug[f'roll_mean_{w}'] = roll_mean\n",
    "    \n",
    "    # Calculate rolling std with explicit handling of NaN values\n",
    "    roll_std = df_debug['rms'].rolling(window=w, min_periods=1).std()\n",
    "    roll_std = roll_std.fillna(0)  # Explicitly fill NaN values with 0\n",
    "    logger.info(f\"Rolling std (window={w}) - First 5 values: {roll_std.head().tolist()}\")\n",
    "    df_debug[f'roll_std_{w}'] = roll_std\n",
    "    \n",
    "    # Validate calculations\n",
    "    print(f\"\\nValidation for window size {w}:\")\n",
    "    print(f\"Number of NaN values in roll_mean_{w}: {df_debug[f'roll_mean_{w}'].isna().sum()}\")\n",
    "    print(f\"Number of NaN values in roll_std_{w}: {df_debug[f'roll_std_{w}'].isna().sum()}\")\n",
    "\n",
    "# Handle any remaining missing values\n",
    "df_debug = df_debug.bfill().ffill()\n",
    "\n",
    "# Check for any remaining NaN values\n",
    "print(\"\\nFinal NaN check:\")\n",
    "print(df_debug.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2e09a",
   "metadata": {},
   "source": [
    "## 4. Data Validation\n",
    "\n",
    "Check for any anomalies in the processed data, including NaN values, infinite values, and data type consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e5ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 17:22:37,045 - INFO - Starting data validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features Validation:\n",
      "\n",
      "Validating Original Features\n",
      "\n",
      "NaN value counts:\n",
      "No NaN values found\n",
      "\n",
      "Infinite value counts:\n",
      "No infinite values found\n",
      "\n",
      "Data types:\n",
      "mean    float64\n",
      "std     float64\n",
      "rms     float64\n",
      "kurt    float64\n",
      "skew    float64\n",
      "ptp     float64\n",
      "dtype: object\n",
      "\n",
      "Value ranges:\n",
      "\n",
      "mean:\n",
      "count    102400.000000\n",
      "mean         -0.093867\n",
      "std           0.025695\n",
      "min          -0.249000\n",
      "25%          -0.110250\n",
      "50%          -0.093750\n",
      "75%          -0.077250\n",
      "max           0.117750\n",
      "Name: mean, dtype: float64\n",
      "\n",
      "std:\n",
      "count    102400.000000\n",
      "mean          0.071454\n",
      "std           0.024476\n",
      "min           0.009493\n",
      "25%           0.054674\n",
      "50%           0.068296\n",
      "75%           0.084377\n",
      "max           0.280767\n",
      "Name: std, dtype: float64\n",
      "\n",
      "rms:\n",
      "count    102400.000000\n",
      "mean          0.120473\n",
      "std           0.025734\n",
      "min           0.033701\n",
      "25%           0.103064\n",
      "50%           0.118501\n",
      "75%           0.135381\n",
      "max           0.365391\n",
      "Name: rms, dtype: float64\n",
      "\n",
      "kurt:\n",
      "count    102400.000000\n",
      "mean          0.070300\n",
      "std           1.520149\n",
      "min          -2.750019\n",
      "25%          -1.031657\n",
      "50%          -0.282130\n",
      "75%           0.857014\n",
      "max           7.592169\n",
      "Name: kurt, dtype: float64\n",
      "\n",
      "skew:\n",
      "count    102400.000000\n",
      "mean         -0.004213\n",
      "std           0.772385\n",
      "min          -2.733509\n",
      "25%          -0.508784\n",
      "50%          -0.002478\n",
      "75%           0.503495\n",
      "max           2.726810\n",
      "Name: skew, dtype: float64\n",
      "\n",
      "ptp:\n",
      "count    102400.000000\n",
      "mean          0.226379\n",
      "std           0.081537\n",
      "min           0.030000\n",
      "25%           0.171000\n",
      "50%           0.215000\n",
      "75%           0.269000\n",
      "max           0.962000\n",
      "Name: ptp, dtype: float64\n",
      "\n",
      "Rolling Statistics Validation:\n",
      "\n",
      "Validating Rolling Statistics\n",
      "\n",
      "NaN value counts:\n",
      "No NaN values found\n",
      "\n",
      "Infinite value counts:\n",
      "No infinite values found\n",
      "\n",
      "Data types:\n",
      "roll_mean_3     float64\n",
      "roll_std_3      float64\n",
      "roll_mean_5     float64\n",
      "roll_std_5      float64\n",
      "roll_mean_10    float64\n",
      "roll_std_10     float64\n",
      "dtype: object\n",
      "\n",
      "Value ranges:\n",
      "\n",
      "roll_mean_3:\n",
      "count    102400.000000\n",
      "mean          0.120473\n",
      "std           0.018616\n",
      "min           0.057073\n",
      "25%           0.107872\n",
      "50%           0.118832\n",
      "75%           0.131053\n",
      "max           0.279063\n",
      "Name: roll_mean_3, dtype: float64\n",
      "\n",
      "roll_std_3:\n",
      "count    102400.000000\n",
      "mean          0.018743\n",
      "std           0.011056\n",
      "min           0.000000\n",
      "25%           0.010745\n",
      "50%           0.016958\n",
      "75%           0.024573\n",
      "max           0.137883\n",
      "Name: roll_std_3, dtype: float64\n",
      "\n",
      "roll_mean_5:\n",
      "count    102400.000000\n",
      "mean          0.120473\n",
      "std           0.016550\n",
      "min           0.067868\n",
      "25%           0.109326\n",
      "50%           0.118829\n",
      "75%           0.129542\n",
      "max           0.254767\n",
      "Name: roll_mean_5, dtype: float64\n",
      "\n",
      "roll_std_5:\n",
      "count    102400.000000\n",
      "mean          0.020191\n",
      "std           0.008814\n",
      "min           0.000000\n",
      "25%           0.014054\n",
      "50%           0.018978\n",
      "75%           0.024795\n",
      "max           0.110073\n",
      "Name: roll_std_5, dtype: float64\n",
      "\n",
      "roll_mean_10:\n",
      "count    102400.000000\n",
      "mean          0.120473\n",
      "std           0.014028\n",
      "min           0.080608\n",
      "25%           0.111294\n",
      "50%           0.118906\n",
      "75%           0.127572\n",
      "max           0.239686\n",
      "Name: roll_mean_10, dtype: float64\n",
      "\n",
      "roll_std_10:\n",
      "count    102400.000000\n",
      "mean          0.021632\n",
      "std           0.007015\n",
      "min           0.000000\n",
      "25%           0.016905\n",
      "50%           0.020631\n",
      "75%           0.025178\n",
      "max           0.080680\n",
      "Name: roll_std_10, dtype: float64\n",
      "\n",
      "Infinite value counts:\n",
      "No infinite values found\n",
      "\n",
      "Data types:\n",
      "roll_mean_3     float64\n",
      "roll_std_3      float64\n",
      "roll_mean_5     float64\n",
      "roll_std_5      float64\n",
      "roll_mean_10    float64\n",
      "roll_std_10     float64\n",
      "dtype: object\n",
      "\n",
      "Value ranges:\n",
      "\n",
      "roll_mean_3:\n",
      "count    102400.000000\n",
      "mean          0.120473\n",
      "std           0.018616\n",
      "min           0.057073\n",
      "25%           0.107872\n",
      "50%           0.118832\n",
      "75%           0.131053\n",
      "max           0.279063\n",
      "Name: roll_mean_3, dtype: float64\n",
      "\n",
      "roll_std_3:\n",
      "count    102400.000000\n",
      "mean          0.018743\n",
      "std           0.011056\n",
      "min           0.000000\n",
      "25%           0.010745\n",
      "50%           0.016958\n",
      "75%           0.024573\n",
      "max           0.137883\n",
      "Name: roll_std_3, dtype: float64\n",
      "\n",
      "roll_mean_5:\n",
      "count    102400.000000\n",
      "mean          0.120473\n",
      "std           0.016550\n",
      "min           0.067868\n",
      "25%           0.109326\n",
      "50%           0.118829\n",
      "75%           0.129542\n",
      "max           0.254767\n",
      "Name: roll_mean_5, dtype: float64\n",
      "\n",
      "roll_std_5:\n",
      "count    102400.000000\n",
      "mean          0.020191\n",
      "std           0.008814\n",
      "min           0.000000\n",
      "25%           0.014054\n",
      "50%           0.018978\n",
      "75%           0.024795\n",
      "max           0.110073\n",
      "Name: roll_std_5, dtype: float64\n",
      "\n",
      "roll_mean_10:\n",
      "count    102400.000000\n",
      "mean          0.120473\n",
      "std           0.014028\n",
      "min           0.080608\n",
      "25%           0.111294\n",
      "50%           0.118906\n",
      "75%           0.127572\n",
      "max           0.239686\n",
      "Name: roll_mean_10, dtype: float64\n",
      "\n",
      "roll_std_10:\n",
      "count    102400.000000\n",
      "mean          0.021632\n",
      "std           0.007015\n",
      "min           0.000000\n",
      "25%           0.016905\n",
      "50%           0.020631\n",
      "75%           0.025178\n",
      "max           0.080680\n",
      "Name: roll_std_10, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive data validation\n",
    "logger.info(\"Starting data validation\")\n",
    "\n",
    "def validate_dataframe(df, name=\"DataFrame\"):\n",
    "    \"\"\"Validate a DataFrame for common issues\"\"\"\n",
    "    print(f\"\\nValidating {name}\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    nan_counts = df.isna().sum()\n",
    "    print(\"\\nNaN value counts:\")\n",
    "    print(nan_counts[nan_counts > 0] if any(nan_counts > 0) else \"No NaN values found\")\n",
    "    \n",
    "    # Check for infinite values\n",
    "    inf_counts = df.isin([np.inf, -np.inf]).sum()\n",
    "    print(\"\\nInfinite value counts:\")\n",
    "    print(inf_counts[inf_counts > 0] if any(inf_counts > 0) else \"No infinite values found\")\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Check for very large or small values\n",
    "    print(\"\\nValue ranges:\")\n",
    "    for col in df.select_dtypes(include=np.number).columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df[col].describe())\n",
    "\n",
    "# Validate original features\n",
    "print(\"Original Features Validation:\")\n",
    "validate_dataframe(df[['mean', 'std', 'rms', 'kurt', 'skew', 'ptp']], \"Original Features\")\n",
    "\n",
    "# Validate rolling statistics\n",
    "print(\"\\nRolling Statistics Validation:\")\n",
    "roll_cols = [col for col in df_debug.columns if col.startswith('roll_')]\n",
    "validate_dataframe(df_debug[roll_cols], \"Rolling Statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7678c9",
   "metadata": {},
   "source": [
    "## 5. Feature Scaling Validation\n",
    "\n",
    "Test the StandardScaler implementation and verify the scaled features are within expected ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test feature scaling\n",
    "logger.info(\"Starting feature scaling validation\")\n",
    "\n",
    "# Prepare features for scaling\n",
    "X = df_debug.drop(columns=['time'])\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Validate scaling results\n",
    "print(\"Scaling Validation:\")\n",
    "print(\"\\nScaled features summary:\")\n",
    "print(X_scaled_df.describe())\n",
    "\n",
    "# Check if scaled features have mean ≈ 0 and std ≈ 1\n",
    "print(\"\\nVerifying scaling properties:\")\n",
    "for column in X_scaled_df.columns:\n",
    "    mean = X_scaled_df[column].mean()\n",
    "    std = X_scaled_df[column].std()\n",
    "    print(f\"\\n{column}:\")\n",
    "    print(f\"Mean: {mean:.6f} (should be close to 0)\")\n",
    "    print(f\"Std:  {std:.6f} (should be close to 1)\")\n",
    "    \n",
    "    # Check for any values outside expected range\n",
    "    outside_range = np.sum(np.abs(X_scaled_df[column]) > 5)\n",
    "    if outside_range > 0:\n",
    "        print(f\"Warning: {outside_range} values more than 5 standard deviations from mean\")\n",
    "\n",
    "# Save scaler for consistency\n",
    "try:\n",
    "    import joblib\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    joblib.dump(scaler, \"../models/scaler_debug.joblib\")\n",
    "    logger.info(\"Saved scaler to models/scaler_debug.joblib\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error saving scaler: {str(e)}\")\n",
    "\n",
    "# Verify inverse transform works correctly\n",
    "X_inverse = scaler.inverse_transform(X_scaled)\n",
    "max_diff = np.max(np.abs(X_inverse - X.values))\n",
    "print(f\"\\nMaximum difference after inverse transform: {max_diff:.10f}\")\n",
    "if max_diff > 1e-10:\n",
    "    logger.warning(\"Large difference found in inverse transform\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
